"""
CityLens V7 - Hybrid Pipeline + ReAct Discovery

æ ¸å¿ƒæ”¹è¿›ï¼š
- Layer 1/2/4 ä¿æŒä¸å˜ï¼ˆPipelineç»“æ„æ¸…æ™°ï¼‰
- Layer 3 å¼•å…¥ ReAct Discovery Loopï¼ˆåŠ¨æ€è¿½é—®ï¼‰

Layer 3 æ”¹è¿›ï¼š
- ä»"é¢„è®¾å¹¶è¡Œæœç´¢"æ”¹ä¸º"ç§å­å¹¶è¡Œ + åŠ¨æ€æ·±æŒ–"
- å¼•å…¥ surprise_score åˆ¤æ–­å‘ç°ä»·å€¼
- è®¾ç½® budget é˜²æ­¢æ— é™å¾ªç¯
- åŠ¨æ€è¿½é—®ï¼šå‘ç°å¼•å‡ºæ–°é—®é¢˜æ—¶ç»§ç»­æ¢ç´¢

æµç¨‹å›¾ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: Triage (ä¿æŒä¸å˜)                                         â”‚
â”‚  "æœ‰æ„æ€å—ï¼Ÿ" â†’ none/surface/deep                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: Parallel Observation (ä¿æŒä¸å˜)                           â”‚
â”‚  å¤šè§†è§’å¹¶è¡Œè§‚å¯Ÿ â†’ æå–"ç ”ç©¶ç§å­"                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Layer 3: ReAct Discovery Loop ã€æ ¸å¿ƒæ”¹åŠ¨ã€‘                         â•‘
â•‘                                                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚ Phase 1: å¹¶è¡Œæœç´¢æ‰€æœ‰ç§å­                                    â”‚   â•‘
â•‘  â”‚ seeds: ["ç‹¬ç‰¹å…¥å£è®¾è®¡", "å±‹é¡¶æ¤è¢«", ...]                     â”‚   â•‘
â•‘  â”‚         â†“ å¹¶è¡Œ                                              â”‚   â•‘
â•‘  â”‚ initial_discoveries: [{fact, surprise_score, followup}, ...] â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                               â”‚                                     â•‘
â•‘                               â–¼                                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚ Phase 2: åŠ¨æ€æ·±æŒ– (ReAct Loop)                               â”‚   â•‘
â•‘  â”‚                                                             â”‚   â•‘
â•‘  â”‚ while budget > 0 and has_followup:                          â”‚   â•‘
â•‘  â”‚     THOUGHT: å“ªä¸ªå‘ç°å€¼å¾—è¿½é—®ï¼Ÿ                              â”‚   â•‘
â•‘  â”‚     ACTION:  æœç´¢ followup é—®é¢˜                              â”‚   â•‘
â•‘  â”‚     OBSERVE: åˆ†æç»“æœï¼Œè¯„ä¼° surprise_score                   â”‚   â•‘
â•‘  â”‚     DECIDE:  æ–°å‘ç°æ˜¯å¦äº§ç”Ÿæ›´å¤šé—®é¢˜ï¼Ÿ                         â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4: Synthesize (ä¿æŒä¸å˜)                                     â”‚
â”‚  åŸºäºæ‰€æœ‰å‘ç°ç”Ÿæˆæ´è§                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

import asyncio
import time
import os
from typing import Optional, Literal
from dataclasses import dataclass, field
from pydantic import BaseModel

from google import genai
from google.genai import types

from src.utils.llm import parse_json_response
from src.utils.location import get_nearby_pois, format_pois_for_prompt
from src.agents.director import PERSPECTIVE_POOL
from src.utils.logger import llm_logger, analysis_logger


# ============================================================
# é…ç½®
# ============================================================

MODEL = "gemini-3-flash-preview"
MAX_DISCOVERY_BUDGET = 5  # æœ€å¤šæœç´¢è½®æ•°
MIN_SURPRISE_FOR_FOLLOWUP = 0.6  # è¶…è¿‡æ­¤åˆ†æ•°æ‰æ·±æŒ–


# ============================================================
# æ•°æ®ç»“æ„
# ============================================================

@dataclass
class ResearchSeed:
    """ä» Surface Analysis æå–çš„ç ”ç©¶ç§å­"""
    observation: str      # "å…¥å£ä½¿ç”¨äº†å¤§é‡é•œé¢ææ–™"
    hypothesis: str       # "å¯èƒ½æ˜¯æŸç§ç‰¹æ®Šè®¾è®¡æ‰‹æ³•"
    perspective: str      # æ¥æºè§†è§’
    priority: float = 0.5 # ä¼˜å…ˆçº§ 0-1


@dataclass
class Discovery:
    """ä¸€æ¬¡æœç´¢çš„å‘ç°"""
    query: str                    # æœç´¢è¯
    fact: str                     # æ ¸å¿ƒäº‹å®
    detail: str                   # è¯¦ç»†å†…å®¹
    source_summary: str           # æ¥æºæ‘˜è¦
    surprise_score: float         # æƒŠäººç¨‹åº¦ 0-1
    followup: Optional[str] = None  # äº§ç”Ÿçš„æ–°é—®é¢˜
    depth: int = 0                # æœç´¢æ·±åº¦ (0=åˆå§‹, 1=è¿½é—®, 2=å†è¿½é—®...)


@dataclass
class PlannerDecision:
    """Planner çš„å†³ç­–"""
    action: str           # "search" | "done"
    query: Optional[str]  # å¦‚æœ searchï¼Œæœä»€ä¹ˆ
    reasoning: str        # ä¸ºä»€ä¹ˆè¿™æ ·å†³å®š


# ============================================================
# è¿›åº¦å±•ç¤º
# ============================================================

class Colors:
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    DIM = '\033[2m'


class ProgressDisplay:
    def __init__(self):
        self.start_time = time.time()

    def header(self, text: str):
        print(f"\n{Colors.BOLD}{'â•' * 70}")
        print(f"  {text}")
        print(f"{'â•' * 70}{Colors.ENDC}")

    def layer(self, num: int, name: str, desc: str):
        elapsed = time.time() - self.start_time
        print(f"\n{Colors.CYAN}â”Œ{'â”€' * 68}â”{Colors.ENDC}")
        print(f"{Colors.CYAN}â”‚{Colors.BOLD} Layer {num}: {name} {Colors.ENDC}{Colors.DIM}@ {elapsed:.1f}s{Colors.ENDC}")
        print(f"{Colors.CYAN}â”‚{Colors.ENDC} {desc}")
        print(f"{Colors.CYAN}â””{'â”€' * 68}â”˜{Colors.ENDC}")

    def phase(self, name: str):
        print(f"\n  {Colors.BOLD}â–¸ {name}{Colors.ENDC}")

    def task(self, name: str, result: str = "", status: str = "success"):
        icon = {"success": "âœ“", "error": "âœ—", "pending": "â—‹", "thinking": "?"}.get(status, "Â·")
        color = {"success": Colors.GREEN, "error": Colors.RED, "thinking": Colors.YELLOW}.get(status, Colors.DIM)
        result_str = f" â†’ {result}" if result else ""
        print(f"    {color}{icon}{Colors.ENDC} {name}{result_str}")

    def react_thought(self, thought: str):
        print(f"    {Colors.YELLOW}ğŸ’­ THOUGHT:{Colors.ENDC} {thought}")

    def react_action(self, action: str):
        print(f"    {Colors.BLUE}ğŸ” ACTION:{Colors.ENDC} {action}")

    def react_observe(self, observation: str, score: float):
        score_bar = "â˜…" * int(score * 5) + "â˜†" * (5 - int(score * 5))
        print(f"    {Colors.GREEN}ğŸ‘ OBSERVE:{Colors.ENDC} {observation}")
        print(f"             {Colors.DIM}surprise: {score_bar} ({score:.2f}){Colors.ENDC}")

    def react_decide(self, decision: str):
        print(f"    {Colors.CYAN}â†’ DECIDE:{Colors.ENDC} {decision}")

    def discovery(self, d: Discovery):
        depth_marker = "â””" + "â”€" * d.depth + "â–¸" if d.depth > 0 else "â–¸"
        score_display = f"[{'â˜…' * int(d.surprise_score * 5)}{'â˜†' * (5 - int(d.surprise_score * 5))}]"
        print(f"    {Colors.GREEN}{depth_marker}{Colors.ENDC} {d.fact[:60]}... {Colors.DIM}{score_display}{Colors.ENDC}")

    def timing(self, timings: dict):
        print(f"\n{Colors.BOLD}{'â”€' * 70}")
        print(f"  â±ï¸  è€—æ—¶æ€»ç»“")
        print(f"{'â”€' * 70}{Colors.ENDC}")
        total = timings.get("total", 1)
        for name, t in sorted(timings.items(), key=lambda x: -x[1]):
            if name == "total":
                continue
            pct = (t / total * 100)
            bar = "â–ˆ" * int(pct / 3) + "â–‘" * (33 - int(pct / 3))
            print(f"  {name:20s} {bar} {t:5.1f}s ({pct:4.1f}%)")
        print(f"{'â”€' * 70}")
        print(f"  {Colors.BOLD}æ€»è®¡: {total:.1f}s{Colors.ENDC}")


progress = ProgressDisplay()


# ============================================================
# å¼‚æ­¥ LLM å·¥å…·
# ============================================================

def get_client() -> genai.Client:
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("è¯·è®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡")
    return genai.Client(api_key=api_key)


class LLMError(Exception):
    """LLM API è°ƒç”¨é”™è¯¯"""
    def __init__(self, message: str, retryable: bool = False):
        super().__init__(message)
        self.retryable = retryable


async def llm_with_image(
    prompt: str,
    image_data: bytes,
    json_mode: bool = False,
    max_retries: int = 2,
    timeout_seconds: float = 60.0,
) -> str:
    """
    è°ƒç”¨ Gemini API åˆ†æå›¾ç‰‡ï¼Œå¸¦é”™è¯¯å¤„ç†å’Œé‡è¯•

    Args:
        prompt: æç¤ºè¯
        image_data: å›¾ç‰‡æ•°æ®
        json_mode: æ˜¯å¦è¿”å› JSON
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        timeout_seconds: è¶…æ—¶æ—¶é—´

    Returns:
        æ¨¡å‹è¾“å‡ºæ–‡æœ¬

    Raises:
        LLMError: API è°ƒç”¨å¤±è´¥
    """
    client = get_client()
    config = types.GenerateContentConfig(temperature=0.5, max_output_tokens=4096)
    if json_mode:
        config.response_mime_type = "application/json"

    last_error = None

    for attempt in range(max_retries + 1):
        try:
            # å¸¦è¶…æ—¶çš„ API è°ƒç”¨
            async with asyncio.timeout(timeout_seconds):
                response = await client.aio.models.generate_content(
                    model=MODEL,
                    contents=[types.Content(role="user", parts=[
                        types.Part.from_text(text=prompt),
                        types.Part.from_bytes(data=image_data, mime_type="image/jpeg"),
                    ])],
                    config=config,
                )

            # æ£€æŸ¥ç©ºå“åº”
            if not response.text:
                llm_logger.warning(f"LLM è¿”å›ç©ºå“åº” (attempt {attempt + 1})")
                if attempt < max_retries:
                    await asyncio.sleep(1.0 * (attempt + 1))  # é€’å¢å»¶è¿Ÿ
                    continue
                raise LLMError("LLM è¿”å›ç©ºå“åº”", retryable=True)

            return response.text

        except asyncio.TimeoutError:
            last_error = LLMError(f"API è°ƒç”¨è¶…æ—¶ ({timeout_seconds}s)", retryable=True)
            llm_logger.warning(f"LLM è¶…æ—¶ (attempt {attempt + 1}/{max_retries + 1})")

        except Exception as e:
            error_str = str(e).lower()
            # åˆ¤æ–­æ˜¯å¦å¯é‡è¯•
            retryable = any(x in error_str for x in ["429", "500", "503", "timeout", "rate"])

            if "401" in error_str or "invalid" in error_str:
                # è®¤è¯é”™è¯¯ï¼Œä¸é‡è¯•
                llm_logger.error(f"LLM è®¤è¯é”™è¯¯: {e}")
                raise LLMError(f"API è®¤è¯å¤±è´¥: {e}", retryable=False)

            last_error = LLMError(str(e), retryable=retryable)
            llm_logger.warning(f"LLM é”™è¯¯ (attempt {attempt + 1}): {e}")

        # é‡è¯•å‰ç­‰å¾…
        if attempt < max_retries:
            wait_time = 2.0 * (attempt + 1)  # 2s, 4s, 6s...
            llm_logger.info(f"ç­‰å¾… {wait_time}s åé‡è¯•...")
            await asyncio.sleep(wait_time)

    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
    llm_logger.error(f"LLM è°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {last_error}")
    raise last_error or LLMError("æœªçŸ¥é”™è¯¯")


async def llm_text(
    prompt: str,
    json_mode: bool = False,
    temperature: float = 0.5,
    max_retries: int = 2,
    timeout_seconds: float = 45.0,
) -> str:
    """
    è°ƒç”¨ Gemini APIï¼ˆçº¯æ–‡æœ¬ï¼‰ï¼Œå¸¦é”™è¯¯å¤„ç†å’Œé‡è¯•

    Args:
        prompt: æç¤ºè¯
        json_mode: æ˜¯å¦è¿”å› JSON
        temperature: æ¸©åº¦å‚æ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        timeout_seconds: è¶…æ—¶æ—¶é—´

    Returns:
        æ¨¡å‹è¾“å‡ºæ–‡æœ¬

    Raises:
        LLMError: API è°ƒç”¨å¤±è´¥
    """
    client = get_client()
    config = types.GenerateContentConfig(temperature=temperature, max_output_tokens=4096)
    if json_mode:
        config.response_mime_type = "application/json"

    last_error = None

    for attempt in range(max_retries + 1):
        try:
            async with asyncio.timeout(timeout_seconds):
                response = await client.aio.models.generate_content(
                    model=MODEL,
                    contents=[types.Content(role="user", parts=[types.Part.from_text(text=prompt)])],
                    config=config,
                )

            if not response.text:
                llm_logger.warning(f"LLM text è¿”å›ç©ºå“åº” (attempt {attempt + 1})")
                if attempt < max_retries:
                    await asyncio.sleep(1.0 * (attempt + 1))
                    continue
                raise LLMError("LLM è¿”å›ç©ºå“åº”", retryable=True)

            return response.text

        except asyncio.TimeoutError:
            last_error = LLMError(f"API è°ƒç”¨è¶…æ—¶ ({timeout_seconds}s)", retryable=True)
            llm_logger.warning(f"LLM text è¶…æ—¶ (attempt {attempt + 1})")

        except LLMError:
            raise  # ç›´æ¥ä¼ é€’ LLMError

        except Exception as e:
            error_str = str(e).lower()
            retryable = any(x in error_str for x in ["429", "500", "503", "timeout", "rate"])
            last_error = LLMError(str(e), retryable=retryable)
            llm_logger.warning(f"LLM text é”™è¯¯ (attempt {attempt + 1}): {e}")

        if attempt < max_retries:
            wait_time = 2.0 * (attempt + 1)
            await asyncio.sleep(wait_time)

    llm_logger.error(f"LLM text è°ƒç”¨å¤±è´¥: {last_error}")
    raise last_error or LLMError("æœªçŸ¥é”™è¯¯")


async def search_grounding(query: str, context: str = "", timeout_seconds: float = 30.0) -> dict:
    """
    ä½¿ç”¨ Google Search è¿›è¡Œæœç´¢ï¼Œå¸¦è¶…æ—¶å’Œé”™è¯¯å¤„ç†

    Args:
        query: æœç´¢æŸ¥è¯¢
        context: èƒŒæ™¯ä¸Šä¸‹æ–‡
        timeout_seconds: è¶…æ—¶æ—¶é—´

    Returns:
        {"answer": str, "sources": list, "error": Optional[str]}
    """
    client = get_client()
    prompt = f"""è¯·æœç´¢å¹¶å›ç­”ï¼š{query}
{f"èƒŒæ™¯ï¼š{context}" if context else ""}
æä¾›å‡†ç¡®ã€æœ‰æ·±åº¦çš„å›ç­”ï¼ŒåŒ…å«å…·ä½“ç»†èŠ‚ã€‚ç”¨ä¸­æ–‡å›ç­”ã€‚"""

    try:
        async with asyncio.timeout(timeout_seconds):
            response = await client.aio.models.generate_content(
                model=MODEL,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.3,
                    max_output_tokens=2048,
                    tools=[types.Tool(google_search=types.GoogleSearch())],
                ),
            )

        sources = []
        if response.candidates and response.candidates[0].grounding_metadata:
            metadata = response.candidates[0].grounding_metadata
            if metadata.grounding_chunks:
                for chunk in metadata.grounding_chunks:
                    if hasattr(chunk, 'web') and chunk.web:
                        sources.append(getattr(chunk.web, 'title', ''))

        answer = response.text or ""
        if not answer:
            llm_logger.warning(f"æœç´¢è¿”å›ç©ºç»“æœ: {query[:50]}...")

        return {"answer": answer, "sources": sources}

    except asyncio.TimeoutError:
        llm_logger.warning(f"æœç´¢è¶…æ—¶ ({timeout_seconds}s): {query[:50]}...")
        return {"answer": "æœç´¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•", "sources": [], "error": "timeout"}

    except Exception as e:
        llm_logger.error(f"æœç´¢å¤±è´¥: {e}")
        return {"answer": "æœç´¢æš‚æ—¶ä¸å¯ç”¨", "sources": [], "error": str(e)}


# ============================================================
# çŠ¶æ€å®šä¹‰
# ============================================================

@dataclass
class AgentState:
    image_data: bytes = b""
    latitude: Optional[float] = None
    longitude: Optional[float] = None
    location_context: str = ""

    # ç”¨æˆ·è¾“å…¥ï¼ˆPlan Bï¼‰
    user_description: str = ""  # ç”¨æˆ·å¯¹ç…§ç‰‡çš„æè¿°
    photo_type: str = "auto"    # auto/building/abstract/other
    has_markup: bool = False    # å›¾ç‰‡æ˜¯å¦åŒ…å«ç”¨æˆ·æ ‡è®°çš„å¥½å¥‡åŒºåŸŸ

    # Layer 1
    perception: str = ""
    interest_level: str = "none"
    interest_reason: str = ""
    needs_location: bool = True  # Plan A: æ˜¯å¦éœ€è¦ä½ç½®ä¿¡æ¯
    user_specified_location: str = ""  # ç”¨æˆ·æ˜ç¡®æŒ‡å®šçš„åœ°ç‚¹ï¼ˆä» user_description æå–ï¼‰
    suggested_perspectives: list = field(default_factory=list)

    # Layer 2
    research_seeds: list = field(default_factory=list)  # List[ResearchSeed]
    surface_findings: list = field(default_factory=list)

    # Layer 3 - ReAct Discovery
    discoveries: list = field(default_factory=list)  # List[Discovery]
    discovery_budget_used: int = 0
    react_trace: list = field(default_factory=list)  # è®°å½• ReAct è¿‡ç¨‹

    # Layer 4
    final_response: dict = field(default_factory=dict)
    response_type: str = "nothing"

    timings: dict = field(default_factory=dict)
    error: Optional[str] = None


# ============================================================
# Layer 1: Triage (ä¿æŒä¸å˜)
# ============================================================

async def layer1_triage(state: AgentState) -> AgentState:
    progress.layer(1, "Triage", "åˆ¤æ–­è¿™å¼ ç…§ç‰‡æ˜¯å¦æœ‰å€¼å¾—æ¢ç´¢çš„å†…å®¹")

    # æ„å»ºç”¨æˆ·è¾“å…¥ä¸Šä¸‹æ–‡ï¼ˆPlan Bï¼‰
    user_context = ""
    if state.user_description:
        user_context += f"\n## ç”¨æˆ·æè¿°\n{state.user_description}"
    if state.photo_type != "auto":
        type_hints = {
            "building": "ç”¨æˆ·è¡¨ç¤ºè¿™æ˜¯å»ºç­‘/åŸå¸‚ç›¸å…³ç…§ç‰‡",
            "abstract": "ç”¨æˆ·è¡¨ç¤ºè¿™æ˜¯æŠ½è±¡/è‰ºæœ¯æ€§ç…§ç‰‡ï¼Œå¯èƒ½ä¸å…·ä½“åœ°ç‚¹æ— å…³",
            "other": "ç”¨æˆ·æœªæŒ‡å®šç…§ç‰‡ç±»å‹",
        }
        user_context += f"\n## ç…§ç‰‡ç±»å‹æç¤º\n{type_hints.get(state.photo_type, '')}"

    # ç”¨æˆ·æ ‡è®°æç¤º
    markup_context = ""
    if state.has_markup:
        markup_context = """
## é‡è¦ï¼šç”¨æˆ·æ ‡è®°åŒºåŸŸ
å›¾ç‰‡ä¸­å¸¦æœ‰åŠé€æ˜é»„è‰²/æ©™è‰²æ ‡è®°çš„åŒºåŸŸæ˜¯ç”¨æˆ·ç‰¹åˆ«æ„Ÿå…´è¶£çš„éƒ¨åˆ†ã€‚
è¯·ä¼˜å…ˆå…³æ³¨è¿™äº›æ ‡è®°åŒºåŸŸï¼Œå®ƒä»¬åº”è¯¥è¢«è§†ä¸º "deep" çº§åˆ«çš„å…´è¶£ç‚¹ã€‚
å³ä½¿å›¾ç‰‡æ•´ä½“å¹³æ·¡ï¼Œåªè¦æœ‰æ ‡è®°åŒºåŸŸå°±åº”è¯¥æ·±å…¥åˆ†æã€‚
"""

    prompt = f"""ä½ æ˜¯ä¸€ä½å¥½å¥‡çš„è§‚å¯Ÿè€…ã€‚

## æ ¸å¿ƒåŸåˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰
- **åªæè¿°ä½ åœ¨å›¾ç‰‡ä¸­å®é™…çœ‹åˆ°çš„å†…å®¹**
- **ç»å¯¹ç¦æ­¢**çŒœæµ‹ã€æ¨æ–­æˆ–ç¼–é€ å›¾ç‰‡ä¸­ä¸å­˜åœ¨çš„å…ƒç´ 
- å¦‚æœä¸ç¡®å®šæŸä¸ªå…ƒç´ æ˜¯ä»€ä¹ˆï¼Œè¯´"ä¸ç¡®å®š"è€ŒéçŒœæµ‹
- å®å¯é—æ¼ï¼Œä¸å¯ç¼–é€ 

## ä»»åŠ¡
çœ‹è¿™å¼ å›¾ç‰‡ï¼Œåˆ¤æ–­ï¼šæ˜¯å¦æœ‰ä»»ä½•å€¼å¾—æ·±å…¥äº†è§£çš„ä¸œè¥¿ï¼Ÿ
{markup_context}{user_context}
{f"## ä½ç½®ä¿¡æ¯{chr(10)}{state.location_context}" if state.location_context else ""}

## åˆ¤æ–­æ ‡å‡†
- "none": æ™®é€šæ—¥å¸¸åœºæ™¯ï¼Œæ²¡æœ‰ç‹¬ç‰¹å…ƒç´ 
- "surface": æœ‰å…·ä½“å¯è¯†åˆ«çš„äº‹ç‰©ï¼Œè¡¨é¢æœ‰è¶£
- "deep": å¯è¯†åˆ«çš„ç‰¹å®šå»ºç­‘/åœ°ç‚¹/ä½œå“ï¼Œå€¼å¾—æ·±æŒ–

## æ˜¯å¦éœ€è¦ä½ç½®ä¿¡æ¯ (needs_location)
åˆ¤æ–­è¿™å¼ ç…§ç‰‡æ˜¯å¦éœ€è¦é€šè¿‡åœ°ç†ä½ç½®æ¥å¢å¼ºåˆ†æï¼š
- true: ç…§ç‰‡åŒ…å«å»ºç­‘ã€åº—é“ºã€è¡—é“ã€åœ°æ ‡ç­‰ï¼Œä½ç½®ä¿¡æ¯èƒ½å¸®åŠ©è¯†åˆ«å…·ä½“åœ°ç‚¹
- false: ç…§ç‰‡æ˜¯æŠ½è±¡çš„ï¼ˆå…‰å½±ã€çº¹ç†ã€è‰ºæœ¯æ„å›¾ï¼‰ã€æˆ–ä¸»ä½“ä¸åœ°ç‚¹æ— å…³ï¼ˆé£Ÿç‰©ç‰¹å†™ã€äº§å“ã€è‡ªç„¶æ™¯è§‚ç»†èŠ‚ï¼‰

## å¯ç”¨è§†è§’
{chr(10).join([f"- {pid}: {p['name']}" for pid, p in PERSPECTIVE_POOL.items()])}

## è¾“å‡º JSON
{{
    "perception": "ç®€çŸ­æè¿°ä½ å®é™…çœ‹åˆ°çš„å†…å®¹ï¼ˆ1å¥è¯ï¼‰",
    "interest_level": "none/surface/deep",
    "interest_reason": "åˆ¤æ–­åŸå› ï¼ˆ1å¥è¯ï¼‰",
    "needs_location": true/false,
    "location_reason": "ä¸ºä»€ä¹ˆéœ€è¦/ä¸éœ€è¦ä½ç½®ä¿¡æ¯ï¼ˆ1å¥è¯ï¼‰",
    "user_specified_location": "å¦‚æœç”¨æˆ·åœ¨æè¿°ä¸­æ˜ç¡®æåˆ°äº†åœ°ç‚¹åç§°ï¼Œæå–å‡ºæ¥ï¼›å¦åˆ™ä¸ºç©ºå­—ç¬¦ä¸²",
    "suggested_perspectives": ["perspective_id", ...]
}}

**å…³äº user_specified_location**ï¼š
- å¦‚æœç”¨æˆ·è¯´"åœ°ç‚¹åœ¨ç§©çˆ¶ç¥ç¤¾"ï¼Œåˆ™æå–"ç§©çˆ¶ç¥ç¤¾"
- å¦‚æœç”¨æˆ·è¯´"è¿™æ˜¯ä¸œäº¬å¡”é™„è¿‘æ‹çš„"ï¼Œåˆ™æå–"ä¸œäº¬å¡”"
- å¦‚æœç”¨æˆ·æ²¡æœ‰æåˆ°å…·ä½“åœ°ç‚¹ï¼Œåˆ™å¡«ç©ºå­—ç¬¦ä¸² ""
"""

    try:
        response = await llm_with_image(prompt, state.image_data, json_mode=True)
        result = parse_json_response(response, {})

        # ç¡®ä¿ result æ˜¯ dict
        if not isinstance(result, dict):
            result = {}

        state.perception = result.get("perception", "")
        state.interest_level = result.get("interest_level", "none")
        state.interest_reason = result.get("interest_reason", "")
        state.needs_location = result.get("needs_location", True)  # é»˜è®¤éœ€è¦ä½ç½®
        state.user_specified_location = result.get("user_specified_location", "")
        state.suggested_perspectives = result.get("suggested_perspectives", [])

        # å¦‚æœç”¨æˆ·æ˜ç¡®æŒ‡å®šäº† abstract ç±»å‹ï¼Œå¼ºåˆ¶ä¸éœ€è¦ä½ç½®
        if state.photo_type == "abstract":
            state.needs_location = False

        level_display = {"none": "æ— ç‰¹åˆ«å‘ç°", "surface": "è¡¨é¢æœ‰è¶£", "deep": "å€¼å¾—æ·±æŒ–"}
        progress.task("åˆ†æå›¾ç‰‡", state.perception)
        progress.task("åˆ¤æ–­ç»“æœ", f"{level_display.get(state.interest_level, '?')} - {state.interest_reason}")

        location_status = "éœ€è¦" if state.needs_location else "ä¸éœ€è¦"
        location_reason = result.get("location_reason", "")
        progress.task("ä½ç½®ä¿¡æ¯", f"{location_status} - {location_reason}")

        # æ˜¾ç¤ºç”¨æˆ·æŒ‡å®šçš„åœ°ç‚¹
        if state.user_specified_location:
            progress.task("ç”¨æˆ·æŒ‡å®šåœ°ç‚¹", f"âœ“ {state.user_specified_location}")

    except Exception as e:
        state.error = str(e)
        state.interest_level = "none"

    return state


# ============================================================
# Layer 2: Parallel Observation (æ”¹è¿›ï¼šè¾“å‡ºç ”ç©¶ç§å­)
# ============================================================

async def observe_one_perspective(
    image_data: bytes,
    perspective_id: str,
    perception: str,
    location_context: str,
    user_specified_location: str = "",
    has_markup: bool = False,
) -> tuple[list[dict], list[ResearchSeed]]:
    """è§‚å¯Ÿå¹¶æå–ç ”ç©¶ç§å­"""

    perspective = PERSPECTIVE_POOL.get(perspective_id, {})
    name = perspective.get("name", perspective_id)
    expertise = perspective.get("expertise", "")

    # æ„å»ºåœ°ç‚¹çº¦æŸ
    location_constraint = ""
    if user_specified_location:
        location_constraint = f"""
## é‡è¦ï¼šç”¨æˆ·å·²ç¡®è®¤åœ°ç‚¹
ç”¨æˆ·æ˜ç¡®å‘ŠçŸ¥è¿™æ˜¯ã€Œ{user_specified_location}ã€ã€‚
- **ä¸è¦çŒœæµ‹å…¶ä»–å¯èƒ½çš„åœ°ç‚¹**
- æ‰€æœ‰åˆ†æå’Œå‡è®¾éƒ½åº”åŸºäºè¿™æ˜¯{user_specified_location}çš„å‰æ
- æœç´¢å…³é”®è¯åº”åŒ…å«ã€Œ{user_specified_location}ã€
"""

    # ç”¨æˆ·æ ‡è®°æç¤º
    markup_constraint = ""
    if has_markup:
        markup_constraint = """
## é‡è¦ï¼šç”¨æˆ·æ ‡è®°åŒºåŸŸ
å›¾ç‰‡ä¸­å¸¦æœ‰åŠé€æ˜é»„è‰²/æ©™è‰²æ ‡è®°çš„åŒºåŸŸæ˜¯ç”¨æˆ·ç‰¹åˆ«æ„Ÿå…´è¶£çš„éƒ¨åˆ†ã€‚
- **ä¼˜å…ˆåˆ†ææ ‡è®°åŒºåŸŸ**ï¼Œè¿™æ˜¯ç”¨æˆ·æœ€æƒ³äº†è§£çš„å†…å®¹
- ä¸ºæ ‡è®°åŒºåŸŸç”Ÿæˆé«˜ä¼˜å…ˆçº§çš„ç ”ç©¶ç§å­ (priority >= 0.8)
- å¦‚æœèƒ½è¯†åˆ«æ ‡è®°åŒºåŸŸçš„å…·ä½“å†…å®¹ï¼Œå°†å…¶ä½œä¸ºä¸»è¦å‘ç°
"""

    prompt = f"""ä½ æ˜¯ä¸€ä½{name}ï¼Œä¸“é•¿äº{expertise}ã€‚

## æ ¸å¿ƒåŸåˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰
- **åªè§‚å¯Ÿå’Œæè¿°å›¾ç‰‡ä¸­å®é™…å­˜åœ¨çš„å…ƒç´ **
- **ç»å¯¹ç¦æ­¢**ç¼–é€ ã€æƒ³è±¡æˆ–æ¨æµ‹å›¾ç‰‡ä¸­ä¸å­˜åœ¨çš„å†…å®¹
- æ¯ä¸ªå‘ç°å¿…é¡»å¯¹åº”å›¾ç‰‡ä¸­**å¯è§çš„**å…·ä½“åŒºåŸŸæˆ–å…ƒç´ 
- å¦‚æœä»ä½ çš„è§†è§’çœ‹ä¸åˆ°å€¼å¾—æ³¨æ„çš„å†…å®¹ï¼Œè¿”å›ç©ºçš„ findings æ•°ç»„
- å®å¯å°‘æŠ¥å‘Šï¼Œä¸å¯ç¼–é€ 
{location_constraint}{markup_constraint}
## èƒŒæ™¯
å›¾ç‰‡å†…å®¹ï¼š{perception}
{f"ä½ç½®ï¼š{location_context}" if location_context else ""}

## ä»»åŠ¡
ä»ä½ çš„ä¸“ä¸šè§†è§’è§‚å¯Ÿå›¾ç‰‡ï¼Œæ‰¾å‡º**å®é™…å¯è§çš„**å€¼å¾—æ¢ç´¢çš„å‘ç°ã€‚
{f"æ³¨æ„ï¼šåœ°ç‚¹å·²ç¡®å®šä¸º{user_specified_location}ï¼Œè¯·å›´ç»•æ­¤åœ°ç‚¹è¿›è¡Œåˆ†æã€‚" if user_specified_location else ""}

## è¾“å‡º JSON
{{
    "findings": [
        {{
            "name": "å‘ç°åç§°ï¼ˆå¿…é¡»æ˜¯å›¾ä¸­å¯è§çš„å…·ä½“äº‹ç‰©ï¼‰",
            "observation": "å®¢è§‚è§‚å¯Ÿï¼ˆåªæè¿°ä½ çœ‹åˆ°çš„ï¼‰",
            "insight": "ä¸“ä¸šè§£è¯»",
            "bounding_box": {{
                "x1": 150,
                "y1": 200,
                "x2": 450,
                "y2": 600
            }},
            "research_seed": {{
                "hypothesis": "è¿™å¯èƒ½æ˜¯ä»€ä¹ˆï¼Ÿéœ€è¦æœç´¢éªŒè¯çš„å‡è®¾",
                "search_query": "å»ºè®®çš„æœç´¢å…³é”®è¯{f'ï¼ˆåº”åŒ…å«{user_specified_location}ï¼‰' if user_specified_location else ''}",
                "priority": 0.8  // ä¼˜å…ˆçº§ 0-1
            }}
        }}
    ]
}}

**bounding_box è¯´æ˜**:
- æ ‡æ³¨å‘ç°å¯¹åº”çš„å›¾ç‰‡åŒºåŸŸï¼Œä½¿ç”¨å½’ä¸€åŒ–åæ ‡ (0-1000)
- x1,y1 æ˜¯å·¦ä¸Šè§’ï¼Œx2,y2 æ˜¯å³ä¸‹è§’
- 0 è¡¨ç¤ºæœ€å·¦/æœ€ä¸Šï¼Œ1000 è¡¨ç¤ºæœ€å³/æœ€ä¸‹
- ä¾‹å¦‚ï¼šå·¦ä¸Šå››åˆ†ä¹‹ä¸€åŒºåŸŸ = {{"x1":0,"y1":0,"x2":500,"y2":500}}

**é‡è¦**ï¼š
- æœ€å¤š 1-2 ä¸ªå‘ç°
- åªæŠ¥å‘Šå›¾ç‰‡ä¸­**æ¸…æ™°å¯è§**çš„å†…å®¹
- å¦‚æœçœ‹ä¸æ¸…æˆ–ä¸ç¡®å®šï¼Œä¸è¦æŠ¥å‘Š
- **å¿…é¡»ä¸ºæ¯ä¸ªå‘ç°æä¾› bounding_box**ï¼Œæ ‡æ³¨è¯¥å‘ç°åœ¨å›¾ç‰‡ä¸­çš„ä½ç½®
{f"- åœ°ç‚¹å·²ç¡®è®¤æ˜¯{user_specified_location}ï¼Œä¸è¦çŒœæµ‹å…¶ä»–åœ°ç‚¹" if user_specified_location else "- å¦‚æœä¸ç¡®å®šåœ°ç‚¹ï¼Œå¯ä»¥åŸºäºè§†è§‰ç‰¹å¾æå‡ºå‡è®¾"}
"""

    try:
        response = await llm_with_image(prompt, image_data, json_mode=True)
        result = parse_json_response(response, {})
        findings = result.get("findings", [])

        seeds = []
        for f in findings:
            f["perspective_id"] = perspective_id
            f["perspective_name"] = name

            if f.get("research_seed"):
                seed_data = f["research_seed"]
                seeds.append(ResearchSeed(
                    observation=f.get("observation", ""),
                    hypothesis=seed_data.get("hypothesis", seed_data.get("search_query", "")),
                    perspective=name,
                    priority=seed_data.get("priority", 0.5),
                ))

        return findings, seeds
    except Exception as e:
        return [], []


async def layer2_observation(state: AgentState) -> AgentState:
    progress.layer(2, "Parallel Observation", "å¤šè§†è§’å¹¶è¡Œè§‚å¯Ÿï¼Œæå–ç ”ç©¶ç§å­")

    perspectives = [p for p in state.suggested_perspectives if p in PERSPECTIVE_POOL]
    if not perspectives:
        perspectives = ["architect", "storyteller"]

    # é™åˆ¶è§†è§’æ•°é‡ä»¥ä¼˜åŒ–æ€§èƒ½
    perspectives = perspectives[:2]

    progress.phase(f"å¹¶è¡Œè§‚å¯Ÿ ({len(perspectives)} ä¸ªè§†è§’)")

    # å¦‚æœç”¨æˆ·æŒ‡å®šäº†åœ°ç‚¹ï¼Œæ˜¾ç¤ºæç¤º
    if state.user_specified_location:
        progress.task("ç”¨æˆ·æŒ‡å®šåœ°ç‚¹", f"âœ“ {state.user_specified_location}ï¼ˆå°†å›´ç»•æ­¤åœ°ç‚¹åˆ†æï¼‰")

    tasks = [
        observe_one_perspective(
            state.image_data, p, state.perception, state.location_context,
            state.user_specified_location,  # ä¼ é€’ç”¨æˆ·æŒ‡å®šçš„åœ°ç‚¹
            state.has_markup,  # ä¼ é€’æ˜¯å¦æœ‰ç”¨æˆ·æ ‡è®°
        )
        for p in perspectives
    ]

    results = await asyncio.gather(*tasks, return_exceptions=True)

    all_findings = []
    all_seeds = []

    for i, result in enumerate(results):
        if isinstance(result, Exception):
            progress.task(f"[{perspectives[i]}]", str(result), "error")
            continue

        findings, seeds = result
        all_findings.extend(findings)
        all_seeds.extend(seeds)

        for f in findings:
            has_seed = "ğŸ”¬" if f.get("research_seed") else "ğŸ‘"
            progress.task(f"[{perspectives[i]}]", f"{has_seed} {f.get('name', '?')}")

    state.surface_findings = all_findings
    state.research_seeds = all_seeds

    progress.phase(f"æå–ç ”ç©¶ç§å­: {len(all_seeds)} ä¸ª")
    for seed in all_seeds:
        print(f"    {Colors.DIM}Â· [{seed.perspective}] {seed.hypothesis[:50]}... (priority: {seed.priority}){Colors.ENDC}")

    return state


# ============================================================
# Layer 3: ReAct Discovery Loop ã€æ ¸å¿ƒæ”¹åŠ¨ã€‘
# ============================================================

async def analyze_search_result(query: str, search_result: dict, context: str) -> Discovery:
    """åˆ†ææœç´¢ç»“æœï¼Œè¯„ä¼° surprise_scoreï¼Œåˆ¤æ–­æ˜¯å¦æœ‰ followup"""

    prompt = f"""åˆ†ææœç´¢ç»“æœï¼Œæå–ä¸ç…§ç‰‡ç›¸å…³çš„å‘ç°ã€‚

## æœç´¢è¯
{query}

## æœç´¢ç»“æœ
{search_result.get('answer', '')[:2000]}

## ç…§ç‰‡ä¸Šä¸‹æ–‡
{context}

## è¯„ä¼°æ ‡å‡†
- surprise_score: è¿™ä¸ªå‘ç°å¯¹æ™®é€šäººæ¥è¯´æœ‰å¤šæƒŠäººï¼Ÿ(0-1)
  - 0.0-0.3: å¸¸è¯†ï¼Œå¤§å®¶éƒ½çŸ¥é“
  - 0.4-0.6: æœ‰ç‚¹æ„æ€ï¼Œä½†ä¸ç®—æƒŠäºº
  - 0.7-0.9: å¾ˆæƒŠäººï¼Œ"åŸæ¥å¦‚æ­¤ï¼"
  - 1.0: æå…¶æƒŠäººï¼Œæ”¹å˜è®¤çŸ¥

- followup: è¿™ä¸ªå‘ç°æ˜¯å¦å¼•å‡ºæ›´æ·±çš„é—®é¢˜ï¼Ÿ
  - å¦‚æœå‘ç°äº†å…·ä½“çš„åç§°/äººç‰©/äº‹ä»¶ï¼Œå¯ä»¥è¿½é—®ç»†èŠ‚
  - å¦‚æœåªæ˜¯æ³›æ³›çš„ä¿¡æ¯ï¼Œä¸éœ€è¦è¿½é—®

## è¾“å‡º JSON
{{
    "fact": "æ ¸å¿ƒäº‹å®ï¼ˆ1å¥è¯ï¼Œæœ€é‡è¦çš„å‘ç°ï¼‰",
    "detail": "è¯¦ç»†å†…å®¹ï¼ˆ2-3å¥è¯ï¼‰",
    "surprise_score": 0.75,
    "followup": "å¼•å‡ºçš„æ–°é—®é¢˜ï¼ˆå¦‚æ— åˆ™ä¸ºnullï¼‰",
    "followup_reason": "ä¸ºä»€ä¹ˆè¦è¿½é—®è¿™ä¸ªé—®é¢˜"
}}
"""

    try:
        response = await llm_text(prompt, json_mode=True)
        result = parse_json_response(response, {})

        # ç¡®ä¿ result æ˜¯ dict
        if not isinstance(result, dict):
            result = {}

        # å¤„ç† sources - å¯èƒ½æ˜¯ dict åˆ—è¡¨æˆ– str åˆ—è¡¨
        sources = search_result.get("sources", [])
        if sources and isinstance(sources[0], dict):
            source_names = [s.get("title", "") for s in sources[:3]]
        else:
            source_names = sources[:3]

        return Discovery(
            query=query,
            fact=result.get("fact", "æœªçŸ¥"),
            detail=result.get("detail", ""),
            source_summary=", ".join(filter(None, source_names)),
            surprise_score=float(result.get("surprise_score", 0.5)),
            followup=result.get("followup") if result.get("followup") else None,
        )
    except Exception as e:
        return Discovery(
            query=query,
            fact=f"åˆ†æå¤±è´¥: {e}",
            detail="",
            source_summary="",
            surprise_score=0.0,
        )


async def planner_decide(
    context: str,
    discoveries: list[Discovery],
    pending_questions: list[str],
    budget_remaining: int,
) -> PlannerDecision:
    """Planner å†³å®šä¸‹ä¸€æ­¥ï¼šç»§ç»­æœç´¢è¿˜æ˜¯ç»“æŸ"""

    discoveries_text = "\n".join([
        f"- [{d.surprise_score:.1f}] {d.fact}" + (f" â†’ è¿½é—®: {d.followup}" if d.followup else "")
        for d in discoveries
    ]) if discoveries else "ï¼ˆæš‚æ— ï¼‰"

    questions_text = "\n".join([f"- {q}" for q in pending_questions]) if pending_questions else "ï¼ˆæš‚æ— ï¼‰"

    prompt = f"""ä½ æ˜¯ CityLens çš„ç ”ç©¶è§„åˆ’è€…ã€‚

## ç…§ç‰‡ä¸Šä¸‹æ–‡
{context}

## å·²æœ‰å‘ç°
{discoveries_text}

## å¾…æ¢ç´¢é—®é¢˜
{questions_text}

## å‰©ä½™æœç´¢æ¬¡æ•°
{budget_remaining}

## å†³ç­–è§„åˆ™
1. å¦‚æœå·²æœ‰ 2-3 ä¸ªé«˜è´¨é‡å‘ç°ï¼ˆsurprise_score > 0.7ï¼‰ï¼Œå¯ä»¥ç»“æŸ
2. å¦‚æœå¾…æ¢ç´¢é—®é¢˜ä¸­æœ‰æ˜æ˜¾å€¼å¾—è¿½é—®çš„ï¼Œç»§ç»­æœç´¢
3. å¦‚æœå‰©ä½™æ¬¡æ•°å°‘ä¸”å·²æœ‰è¶³å¤Ÿå‘ç°ï¼Œç»“æŸ
4. ä¼˜å…ˆè¿½é—®èƒ½æŒ–å‡º"å†·çŸ¥è¯†"çš„é—®é¢˜

## è¾“å‡º JSON
{{
    "action": "search" æˆ– "done",
    "query": "å¦‚æœ searchï¼Œå…·ä½“æœä»€ä¹ˆï¼ˆç²¾ç¡®çš„æœç´¢è¯ï¼‰",
    "reasoning": "ä¸ºä»€ä¹ˆè¿™æ ·å†³å®šï¼ˆ1å¥è¯ï¼‰"
}}
"""

    try:
        response = await llm_text(prompt, json_mode=True, temperature=0.3)
        result = parse_json_response(response, {})

        return PlannerDecision(
            action=result.get("action", "done"),
            query=result.get("query"),
            reasoning=result.get("reasoning", ""),
        )
    except Exception as e:
        return PlannerDecision(action="done", query=None, reasoning=f"å†³ç­–å¤±è´¥: {e}")


async def layer3_react_discovery(state: AgentState) -> AgentState:
    """
    Layer 3: ReAct Discovery Loop

    Phase 1: å¹¶è¡Œæœç´¢æ‰€æœ‰åˆå§‹ç§å­
    Phase 2: åŠ¨æ€è¿½é—®æœ‰ä»·å€¼çš„å‘ç°
    """
    progress.layer(3, "ReAct Discovery", "ç§å­å¹¶è¡Œæœç´¢ + åŠ¨æ€è¿½é—®")

    seeds = state.research_seeds
    if not seeds:
        progress.task("è·³è¿‡", "æ²¡æœ‰ç ”ç©¶ç§å­", "pending")
        return state

    # æ„å»ºæœç´¢ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«ç”¨æˆ·æŒ‡å®šçš„åœ°ç‚¹
    context = f"{state.perception}. {state.interest_reason}"
    if state.user_specified_location:
        context = f"åœ°ç‚¹ï¼š{state.user_specified_location}ã€‚{context}"
        progress.task("æœç´¢ä¸Šä¸‹æ–‡", f"å°†å›´ç»•ã€Œ{state.user_specified_location}ã€è¿›è¡Œæœç´¢")

    discoveries: list[Discovery] = []
    react_trace = []
    budget = MAX_DISCOVERY_BUDGET

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Phase 1: å¹¶è¡Œæœç´¢åˆå§‹ç§å­
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    # æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œå–å‰3ä¸ªï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰
    sorted_seeds = sorted(seeds, key=lambda s: s.priority, reverse=True)[:3]

    progress.phase(f"Phase 1: å¹¶è¡Œæœç´¢åˆå§‹ç§å­ ({len(sorted_seeds)} ä¸ª)")

    async def search_and_analyze(seed: ResearchSeed) -> Discovery:
        # å¦‚æœç”¨æˆ·æŒ‡å®šäº†åœ°ç‚¹ï¼Œå°†å…¶åŠ å…¥æœç´¢è¯
        search_query = seed.hypothesis
        if state.user_specified_location and state.user_specified_location not in search_query:
            search_query = f"{state.user_specified_location} {search_query}"

        search_result = await search_grounding(search_query, seed.observation)
        discovery = await analyze_search_result(search_query, search_result, context)
        discovery.depth = 0
        return discovery

    search_tasks = [search_and_analyze(s) for s in sorted_seeds]
    initial_results = await asyncio.gather(*search_tasks, return_exceptions=True)

    for i, result in enumerate(initial_results):
        if isinstance(result, Exception):
            progress.task(f"æœç´¢ [{sorted_seeds[i].perspective}]", str(result), "error")
        else:
            discoveries.append(result)
            progress.discovery(result)
            react_trace.append({
                "phase": 1,
                "type": "initial_search",
                "query": result.query,
                "surprise_score": result.surprise_score,
                "has_followup": result.followup is not None,
            })

    budget -= len(sorted_seeds)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Phase 2: åŠ¨æ€è¿½é—® (ReAct Loop)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    progress.phase("Phase 2: åŠ¨æ€è¿½é—® (ReAct Loop)")

    # æ”¶é›†æ‰€æœ‰å¾…è¿½é—®çš„é—®é¢˜
    pending_questions = [
        d.followup for d in discoveries
        if d.followup and d.surprise_score >= MIN_SURPRISE_FOR_FOLLOWUP
    ]

    # æ£€æŸ¥ Phase 1 æ˜¯å¦å·²æœ‰è¶³å¤Ÿé«˜è´¨é‡å‘ç°
    high_value_count = sum(1 for d in discoveries if d.surprise_score >= 0.7)
    if high_value_count >= 2:
        progress.task("Phase 1 å·²æœ‰è¶³å¤Ÿå‘ç°", f"{high_value_count} ä¸ªé«˜ä»·å€¼", "pending")
        pending_questions = []  # è·³è¿‡ Phase 2

    iteration = 0
    while budget > 0 and pending_questions and iteration < 2:  # æœ€å¤š2è½®è¿½é—®
        iteration += 1
        print(f"\n    {Colors.DIM}â”€â”€â”€ ReAct è¿­ä»£ {iteration} (å‰©ä½™ budget: {budget}) â”€â”€â”€{Colors.ENDC}")

        # THOUGHT: Planner å†³å®šä¸‹ä¸€æ­¥
        decision = await planner_decide(context, discoveries, pending_questions, budget)
        progress.react_thought(decision.reasoning)

        react_trace.append({
            "phase": 2,
            "iteration": iteration,
            "type": "thought",
            "decision": decision.action,
            "reasoning": decision.reasoning,
        })

        if decision.action == "done":
            progress.react_decide("å‘ç°è¶³å¤Ÿï¼Œç»“æŸæ¢ç´¢")
            break

        # ACTION: æ‰§è¡Œæœç´¢
        progress.react_action(f"æœç´¢: {decision.query}")
        search_result = await search_grounding(decision.query, context)

        # OBSERVE: åˆ†æç»“æœ
        new_discovery = await analyze_search_result(decision.query, search_result, context)
        new_discovery.depth = iteration
        discoveries.append(new_discovery)

        progress.react_observe(new_discovery.fact, new_discovery.surprise_score)

        react_trace.append({
            "phase": 2,
            "iteration": iteration,
            "type": "discovery",
            "query": new_discovery.query,
            "fact": new_discovery.fact,
            "surprise_score": new_discovery.surprise_score,
        })

        # DECIDE: æ›´æ–°å¾…è¿½é—®åˆ—è¡¨
        if new_discovery.followup and new_discovery.surprise_score >= MIN_SURPRISE_FOR_FOLLOWUP:
            pending_questions.append(new_discovery.followup)
            progress.react_decide(f"æ–°é—®é¢˜åŠ å…¥é˜Ÿåˆ—: {new_discovery.followup[:40]}...")
        else:
            progress.react_decide("æ­¤çº¿ç´¢æ¢ç´¢å®Œæ¯•")

        # ç§»é™¤å·²æ¢ç´¢çš„é—®é¢˜
        pending_questions = [q for q in pending_questions if q != decision.query]
        budget -= 1

    # æ€»ç»“
    high_value = [d for d in discoveries if d.surprise_score >= 0.7]
    progress.phase(f"æ¢ç´¢å®Œæˆ: {len(discoveries)} ä¸ªå‘ç°, {len(high_value)} ä¸ªé«˜ä»·å€¼")

    state.discoveries = discoveries
    state.discovery_budget_used = MAX_DISCOVERY_BUDGET - budget
    state.react_trace = react_trace

    return state


# ============================================================
# Layer 4: Synthesize (ä¿æŒä¸å˜ï¼Œä½†ä½¿ç”¨ discoveries)
# ============================================================

async def layer4_synthesize_nothing(state: AgentState) -> AgentState:
    progress.layer(4, "Synthesize", "ç”Ÿæˆå“åº”ï¼ˆæ— ç‰¹åˆ«å‘ç°ï¼‰")

    state.final_response = {
        "type": "nothing",
        "message": f"è¿™å¼ ç…§ç‰‡å±•ç¤ºäº†{state.perception}ã€‚{state.interest_reason}",
        "suggestion": "è¯•è¯•æ‹æ‘„ä¸€äº›ç‹¬ç‰¹çš„å»ºç­‘ã€æœ‰è¶£çš„ç»†èŠ‚å§ï¼",
    }
    state.response_type = "nothing"
    return state


async def layer4_synthesize_surface(state: AgentState) -> AgentState:
    progress.layer(4, "Synthesize", "æ•´åˆè¡¨é¢è§‚å¯Ÿ")

    findings_text = "\n".join([
        f"- [{f.get('perspective_name', '')}] {f.get('name', '')}: {f.get('insight', '')}"
        for f in state.surface_findings
    ])

    prompt = f"""æ•´åˆè§‚å¯Ÿä¸ºç®€æ´æœ‰è¶£çš„å‘ç°ã€‚

## å›¾ç‰‡
{state.perception}

## è§‚å¯Ÿ
{findings_text}

## è¾“å‡º JSON
{{
    "summary": "ä¸€å¥è¯æ€»ç»“",
    "findings": [{{"title": "...", "content": "..."}}],
    "closing": "å¼•å‘æ€è€ƒçš„ä¸€å¥è¯"
}}
"""

    try:
        response = await llm_text(prompt, json_mode=True)
        result = parse_json_response(response, {})

        state.final_response = {
            "type": "surface",
            "summary": result.get("summary", ""),
            "findings": result.get("findings", []),
            "closing": result.get("closing", ""),
        }
        state.response_type = "surface"

        progress.task("ç”Ÿæˆå®Œæˆ", f"{len(result.get('findings', []))} ä¸ªå‘ç°")

    except Exception as e:
        state.error = str(e)

    return state


async def layer4_synthesize_deep(state: AgentState) -> AgentState:
    progress.layer(4, "Synthesize", "ç”Ÿæˆæ·±åº¦æ´è§")

    # æŒ‰ surprise_score æ’åºï¼Œå–æœ€å¥½çš„å‘ç°
    sorted_discoveries = sorted(state.discoveries, key=lambda d: d.surprise_score, reverse=True)

    discoveries_text = "\n".join([
        f"""
### å‘ç° {i+1} (æƒŠäººåº¦: {d.surprise_score:.1f})
- æ ¸å¿ƒäº‹å®: {d.fact}
- è¯¦ç»†å†…å®¹: {d.detail}
- æœç´¢æ·±åº¦: {'åˆå§‹å‘ç°' if d.depth == 0 else f'è¿½é—®ç¬¬{d.depth}å±‚'}
"""
        for i, d in enumerate(sorted_discoveries[:5])
    ])

    # ä¹ŸåŒ…å«è¡¨é¢è§‚å¯Ÿï¼ˆåŒ…å« bounding_box ä¿¡æ¯ï¼‰
    surface_text = "\n".join([
        f"- [{f.get('perspective_name', '')}] {f.get('name', '')}: {f.get('insight', '')} (åŒºåŸŸ: {f.get('bounding_box', 'N/A')})"
        for f in state.surface_findings
    ])

    # æ„å»ºå‘ç°åç§°åˆ° bounding_box çš„æ˜ å°„ï¼Œä¾›åˆæˆæ—¶ä½¿ç”¨
    finding_bboxes = {
        f.get('name', ''): f.get('bounding_box')
        for f in state.surface_findings
        if f.get('bounding_box')
    }

    prompt = f"""ä½ æ˜¯ä¸€ä½çŸ¥è¯†ä¼ æ’­è€…ï¼Œå–„äºæŠŠä¸“ä¸šçŸ¥è¯†å˜å¾—æœ‰è¶£æ˜“æ‡‚ã€‚

## æ ¸å¿ƒåŸåˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰
- **æ‰€æœ‰æ´è§å¿…é¡»åŸºäºå›¾ç‰‡ä¸­å®é™…å¯è§çš„å†…å®¹**
- **ç»å¯¹ç¦æ­¢**ç¼–é€ å›¾ç‰‡ä¸­ä¸å­˜åœ¨çš„å…ƒç´ æˆ–ç»†èŠ‚
- æ¯ä¸ª insight çš„ title å¿…é¡»å¯¹åº”å›¾ç‰‡ä¸­**çœŸå®å­˜åœ¨**çš„è§†è§‰å…ƒç´ 
- å¦‚æœç ”ç©¶å‘ç°ä¸å›¾ç‰‡å†…å®¹ä¸ç¬¦ï¼Œå¿½ç•¥è¯¥å‘ç°
- å®å¯å°‘ç”Ÿæˆæ´è§ï¼Œä¸å¯ç¼–é€ 

## å›¾ç‰‡å†…å®¹
{state.perception}

## æ·±åº¦ç ”ç©¶å‘ç°ï¼ˆéœ€éªŒè¯æ˜¯å¦ä¸å›¾ç‰‡åŒ¹é…ï¼‰
{discoveries_text}

## è¡¨é¢è§‚å¯Ÿ
{surface_text}

## ä»»åŠ¡
åŸºäºè¿™äº›å‘ç°ï¼Œç”Ÿæˆ 2-3 æ¡è®©æ™®é€šäººæƒŠå¹çš„æ´è§ã€‚
**å…³é”®**ï¼šæ¯ä¸ªæ´è§å¿…é¡»èƒ½åœ¨å›¾ç‰‡ä¸­æ‰¾åˆ°å¯¹åº”çš„è§†è§‰è¯æ®ã€‚

## è¾“å‡º JSON
{{
    "insights": [
        {{
            "title": "æ ‡é¢˜ï¼ˆå¿…é¡»å¯¹åº”å›¾ç‰‡ä¸­å¯è§çš„å…·ä½“å…ƒç´ ï¼‰",
            "hook": "å¼€åœºé’©å­ï¼ˆå¼•èµ·å¥½å¥‡çš„é—®é¢˜ï¼‰",
            "explanation": "æ ¸å¿ƒè§£è¯»ï¼ˆ3-4å¥è¯ï¼ŒæŠŠå‘ç°è®²æ¸…æ¥šï¼‰",
            "visual_evidence": "è¿™ä¸ªæ´è§å¯¹åº”å›¾ç‰‡ä¸­çš„å“ªä¸ªå¯è§å…ƒç´ ",
            "source_finding": "å¯¹åº”çš„è¡¨é¢è§‚å¯Ÿåç§°ï¼ˆç”¨äºåŒ¹é…åŒºåŸŸåæ ‡ï¼‰",
            "fun_fact": "å†·çŸ¥è¯†ï¼ˆå¦‚æœæœ‰çš„è¯ï¼Œå¿…é¡»ä¸å›¾ç‰‡ç›¸å…³ï¼‰"
        }}
    ],
    "theme": "ä¸»é¢˜æ€»ç»“ï¼ˆ1å¥è¯ï¼‰",
    "invitation": "é‚€è¯·æ¢ç´¢çš„ä¸€å¥è¯"
}}
"""

    try:
        response = await llm_text(prompt, json_mode=True, temperature=0.7)
        result = parse_json_response(response, {})

        # ä¸ºæ¯ä¸ª insight åŒ¹é… bounding_box
        insights = result.get("insights", [])
        for insight in insights:
            source_name = insight.get("source_finding", "")
            # å°è¯•ç²¾ç¡®åŒ¹é…
            if source_name and source_name in finding_bboxes:
                insight["bounding_box"] = finding_bboxes[source_name]
            else:
                # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆåç§°åŒ…å«å…³ç³»ï¼‰
                for name, bbox in finding_bboxes.items():
                    if name in source_name or source_name in name:
                        insight["bounding_box"] = bbox
                        break

        state.final_response = {
            "type": "deep",
            "insights": insights,
            "theme": result.get("theme", ""),
            "invitation": result.get("invitation", ""),
        }
        state.response_type = "deep"

        progress.task("ç”Ÿæˆå®Œæˆ", f"{len(insights)} æ¡æ´è§")

        for insight in insights:
            bbox_status = "ğŸ“" if insight.get("bounding_box") else "âŒ"
            print(f"    {Colors.GREEN}ğŸ’¡{Colors.ENDC} {Colors.BOLD}{insight.get('title', '')}{Colors.ENDC} {bbox_status}")

    except Exception as e:
        state.error = str(e)

    return state


# ============================================================
# ä¸»æµç¨‹
# ============================================================

async def run_perception_v7(
    image_data: bytes,
    latitude: Optional[float] = None,
    longitude: Optional[float] = None,
    user_description: str = "",
    photo_type: str = "auto",
) -> dict:
    """V7 ä¸»æµç¨‹

    Args:
        image_data: å›¾ç‰‡æ•°æ®
        latitude: çº¬åº¦ï¼ˆå¯é€‰ï¼‰
        longitude: ç»åº¦ï¼ˆå¯é€‰ï¼‰
        user_description: ç”¨æˆ·å¯¹ç…§ç‰‡çš„æè¿°ï¼ˆPlan Bï¼‰
        photo_type: ç…§ç‰‡ç±»å‹ auto/building/abstract/otherï¼ˆPlan Bï¼‰
    """

    total_start = time.time()
    progress.header("ğŸ§ª CityLens V7 - Hybrid Pipeline + ReAct Discovery")

    state = AgentState(
        image_data=image_data,
        latitude=latitude,
        longitude=longitude,
        user_description=user_description,
        photo_type=photo_type,
    )

    timings = {}

    # Layer 1: Triageï¼ˆå…ˆåˆ¤æ–­ï¼Œå†å†³å®šæ˜¯å¦è·å–ä½ç½®ï¼‰
    t1 = time.time()
    state = await layer1_triage(state)
    timings["triage"] = time.time() - t1

    if state.interest_level == "none":
        state = await layer4_synthesize_nothing(state)
        timings["total"] = time.time() - total_start
        state.timings = timings
        progress.timing(timings)
        return _format_result(state)

    # Locationï¼ˆPlan A: ä»…åœ¨éœ€è¦æ—¶è·å–ï¼‰
    if latitude and longitude and state.needs_location:
        loc_start = time.time()
        print(f"\n  {Colors.DIM}ğŸ“ è·å–ä½ç½®ä¿¡æ¯ ({latitude}, {longitude})...{Colors.ENDC}")
        loop = asyncio.get_event_loop()
        state.location_context = await loop.run_in_executor(
            None, lambda: format_pois_for_prompt(get_nearby_pois(latitude, longitude, 100))
        )
        timings["location"] = time.time() - loc_start
    elif latitude and longitude and not state.needs_location:
        print(f"\n  {Colors.DIM}ğŸ“ è·³è¿‡ä½ç½®ä¿¡æ¯ï¼ˆç…§ç‰‡å†…å®¹ä¸åœ°ç‚¹æ— å…³ï¼‰{Colors.ENDC}")
        timings["location"] = 0.0

    # Layer 2: Observation
    t2 = time.time()
    state = await layer2_observation(state)
    timings["observation"] = time.time() - t2

    if not state.research_seeds:
        state = await layer4_synthesize_surface(state)
        timings["total"] = time.time() - total_start
        state.timings = timings
        progress.timing(timings)
        return _format_result(state)

    # Layer 3: ReAct Discovery
    t3 = time.time()
    state = await layer3_react_discovery(state)
    timings["react_discovery"] = time.time() - t3

    # Layer 4: Synthesize
    t4 = time.time()
    state = await layer4_synthesize_deep(state)
    timings["synthesize"] = time.time() - t4

    timings["total"] = time.time() - total_start
    state.timings = timings

    progress.timing(timings)

    return _format_result(state)


def _format_result(state: AgentState) -> dict:
    return {
        "type": state.response_type,
        "perception": state.perception,
        "response": state.final_response,
        "timings": state.timings,
        "error": state.error,
        "process": {
            "interest_level": state.interest_level,
            "needs_location": state.needs_location,  # Plan A: æ˜¯å¦ä½¿ç”¨äº†ä½ç½®ä¿¡æ¯
            "user_specified_location": state.user_specified_location,  # ç”¨æˆ·æŒ‡å®šçš„åœ°ç‚¹
            "seeds_count": len(state.research_seeds),
            "discoveries_count": len(state.discoveries),
            "budget_used": state.discovery_budget_used,
            "react_trace": state.react_trace,
        },
        "user_input": {  # Plan B: ç”¨æˆ·è¾“å…¥
            "description": state.user_description,
            "photo_type": state.photo_type,
        }
    }


# ============================================================
# æµå¼è¿›åº¦ç‰ˆæœ¬ (SSE)
# ============================================================

async def run_perception_v7_streaming(
    image_data: bytes,
    latitude: Optional[float] = None,
    longitude: Optional[float] = None,
    user_description: str = "",
    photo_type: str = "auto",
    has_markup: bool = False,
):
    """æµå¼ç‰ˆæœ¬ - é€šè¿‡ yield è¿”å›è¿›åº¦äº‹ä»¶

    Args:
        has_markup: å¦‚æœä¸º Trueï¼Œè¡¨ç¤ºå›¾ç‰‡åŒ…å«ç”¨æˆ·æ¶‚æŠ¹çš„æ ‡è®°åŒºåŸŸï¼Œ
                   åˆ†ææ—¶ä¼šä¼˜å…ˆå…³æ³¨è¿™äº›åŒºåŸŸ
    """

    total_start = time.time()

    yield {
        "type": "progress",
        "layer": 0,
        "phase": "start",
        "message": "å¼€å§‹åˆ†æ...",
    }

    state = AgentState(
        image_data=image_data,
        latitude=latitude,
        longitude=longitude,
        user_description=user_description,
        photo_type=photo_type,
        has_markup=has_markup,
    )

    timings = {}

    # Layer 1: Triage
    triage_detail = "åˆ†æè¿™å¼ ç…§ç‰‡æ˜¯å¦æœ‰å€¼å¾—æ¢ç´¢çš„å†…å®¹"
    if has_markup:
        triage_detail = "åˆ†æç”¨æˆ·æ ‡è®°çš„æ„Ÿå…´è¶£åŒºåŸŸ"

    yield {
        "type": "progress",
        "layer": 1,
        "phase": "triage",
        "message": "åˆ¤æ–­å›¾ç‰‡å†…å®¹...",
        "detail": triage_detail,
    }

    t1 = time.time()
    state = await layer1_triage(state)
    timings["triage"] = time.time() - t1

    yield {
        "type": "progress",
        "layer": 1,
        "phase": "triage_done",
        "message": f"åˆæ­¥åˆ¤æ–­: {state.perception[:50]}..." if state.perception else "åˆ†æå®Œæˆ",
        "detail": f"å…´è¶£çº§åˆ«: {state.interest_level}",
    }

    if state.interest_level == "none":
        state = await layer4_synthesize_nothing(state)
        timings["total"] = time.time() - total_start
        state.timings = timings
        yield {"type": "result", "success": True, "data": _format_result(state)}
        return

    # Location
    if latitude and longitude and state.needs_location:
        yield {
            "type": "progress",
            "layer": 1,
            "phase": "location",
            "message": f"è·å–ä½ç½®ä¿¡æ¯...",
            "detail": f"åæ ‡: {latitude:.4f}, {longitude:.4f}",
        }
        loc_start = time.time()
        loop = asyncio.get_event_loop()
        state.location_context = await loop.run_in_executor(
            None, lambda: format_pois_for_prompt(get_nearby_pois(latitude, longitude, 100))
        )
        timings["location"] = time.time() - loc_start

    # Layer 2: Observation
    # è·å–å®é™…ä½¿ç”¨çš„è§†è§’åç§°
    perspectives_to_use = [p for p in state.suggested_perspectives if p in PERSPECTIVE_POOL]
    if not perspectives_to_use:
        perspectives_to_use = ["architect", "storyteller"]
    perspectives_to_use = perspectives_to_use[:2]  # é™åˆ¶2ä¸ª

    perspective_names = [PERSPECTIVE_POOL[p]["name"] for p in perspectives_to_use]
    perspectives_detail = "ã€".join(perspective_names) + "è§†è§’å¹¶è¡Œåˆ†æ"

    yield {
        "type": "progress",
        "layer": 2,
        "phase": "observation",
        "message": "å¤šè§†è§’è§‚å¯Ÿä¸­...",
        "detail": perspectives_detail,
    }

    t2 = time.time()
    state = await layer2_observation(state)
    timings["observation"] = time.time() - t2

    seeds_count = len(state.research_seeds)
    yield {
        "type": "progress",
        "layer": 2,
        "phase": "observation_done",
        "message": f"å‘ç° {seeds_count} ä¸ªç ”ç©¶çº¿ç´¢",
        "detail": ", ".join([s.observation[:20] + "..." for s in state.research_seeds[:3]]) if state.research_seeds else "",
    }

    if not state.research_seeds:
        state = await layer4_synthesize_surface(state)

        # ä¸º surface findings æ·»åŠ åˆ†å‰²
        findings_with_bbox = [
            f for f in state.surface_findings
            if f.get("bounding_box")
        ]

        if findings_with_bbox:
            yield {
                "type": "progress",
                "layer": 5,
                "phase": "segmentation",
                "message": f"æå–å…³é”®åŒºåŸŸ...",
                "detail": f"ä¸º {len(findings_with_bbox)} ä¸ªå‘ç°ç”ŸæˆæŠ å›¾",
            }

            try:
                from src.utils.segmentation import segment_region

                for finding in state.surface_findings:
                    bbox = finding.get("bounding_box")
                    if bbox and isinstance(bbox, dict):
                        if all(k in bbox for k in ["x1", "y1", "x2", "y2"]):
                            cropped_image = segment_region(
                                state.image_data,
                                bbox,
                                output_format="png",
                            )
                            if cropped_image:
                                finding["cropped_image"] = cropped_image

                # å°†å¸¦æŠ å›¾çš„ findings æ·»åŠ åˆ° final_response
                state.final_response["surface_findings"] = state.surface_findings
            except Exception as e:
                print(f"[Segmentation] Surface åˆ†å‰²å¤±è´¥: {e}")

        timings["total"] = time.time() - total_start
        state.timings = timings
        yield {"type": "result", "success": True, "data": _format_result(state)}
        return

    # Layer 3: ReAct Discovery
    yield {
        "type": "progress",
        "layer": 3,
        "phase": "discovery",
        "message": "æ·±å…¥æœç´¢ç ”ç©¶ä¸­...",
        "detail": "é€šè¿‡ç½‘ç»œæœç´¢éªŒè¯å’Œæ‰©å±•å‘ç°",
    }

    t3 = time.time()
    state = await layer3_react_discovery(state)
    timings["react_discovery"] = time.time() - t3

    discoveries_count = len(state.discoveries)
    high_value = len([d for d in state.discoveries if d.surprise_score >= 0.7])
    yield {
        "type": "progress",
        "layer": 3,
        "phase": "discovery_done",
        "message": f"å®Œæˆ {discoveries_count} ä¸ªå‘ç°",
        "detail": f"å…¶ä¸­ {high_value} ä¸ªé«˜ä»·å€¼å‘ç°",
    }

    # Layer 4: Synthesize
    yield {
        "type": "progress",
        "layer": 4,
        "phase": "synthesize",
        "message": "ç”Ÿæˆæ´è§æŠ¥å‘Š...",
        "detail": "æ•´åˆæ‰€æœ‰å‘ç°ï¼Œç”Ÿæˆæ·±åº¦åˆ†æ",
    }

    t4 = time.time()
    state = await layer4_synthesize_deep(state)
    timings["synthesize"] = time.time() - t4

    timings["total"] = time.time() - total_start
    state.timings = timings

    insights_count = len(state.final_response.get("insights", [])) if state.final_response else 0
    yield {
        "type": "progress",
        "layer": 4,
        "phase": "complete",
        "message": f"åˆ†æå®Œæˆï¼ç”Ÿæˆ {insights_count} æ¡æ´è§",
        "detail": f"æ€»è€—æ—¶: {timings['total']:.1f}ç§’",
    }

    # Layer 5: Segmentation (ä¸ºæœ‰ bounding_box çš„ insight ç”ŸæˆæŠ å›¾)
    if state.final_response and state.final_response.get("insights"):
        insights_with_bbox = [
            i for i in state.final_response["insights"]
            if i.get("bounding_box")
        ]

        if insights_with_bbox:
            yield {
                "type": "progress",
                "layer": 5,
                "phase": "segmentation",
                "message": f"æå–å…³é”®åŒºåŸŸ...",
                "detail": f"ä¸º {len(insights_with_bbox)} ä¸ªæ´è§ç”ŸæˆæŠ å›¾",
            }

            t5 = time.time()
            try:
                from src.utils.segmentation import segment_region

                for insight in state.final_response["insights"]:
                    bbox = insight.get("bounding_box")
                    if bbox and isinstance(bbox, dict):
                        # ç¡®ä¿ bbox æœ‰æ‰€æœ‰å¿…éœ€çš„é”®
                        if all(k in bbox for k in ["x1", "y1", "x2", "y2"]):
                            cropped_image = segment_region(
                                state.image_data,
                                bbox,
                                output_format="png",
                            )
                            if cropped_image:
                                insight["cropped_image"] = cropped_image

                timings["segmentation"] = time.time() - t5

                # ç»Ÿè®¡æˆåŠŸæŠ å›¾æ•°é‡
                cropped_count = len([
                    i for i in state.final_response["insights"]
                    if i.get("cropped_image")
                ])

                yield {
                    "type": "progress",
                    "layer": 5,
                    "phase": "segmentation_done",
                    "message": f"åŒºåŸŸæå–å®Œæˆ",
                    "detail": f"æˆåŠŸæå– {cropped_count}/{len(insights_with_bbox)} ä¸ªåŒºåŸŸ",
                }
            except Exception as e:
                print(f"[Segmentation] åˆ†å‰²æ­¥éª¤å¤±è´¥: {e}")
                timings["segmentation"] = time.time() - t5
                yield {
                    "type": "progress",
                    "layer": 5,
                    "phase": "segmentation_error",
                    "message": "åŒºåŸŸæå–è·³è¿‡",
                    "detail": str(e)[:50],
                }

    # Update total time after segmentation
    timings["total"] = time.time() - total_start
    state.timings = timings

    # Final result
    yield {"type": "result", "success": True, "data": _format_result(state)}


# åŒæ­¥å…¥å£
def enhance_perception_v7(
    image_data: bytes,
    latitude: Optional[float] = None,
    longitude: Optional[float] = None,
    user_description: str = "",
    photo_type: str = "auto",
) -> dict:
    return asyncio.run(run_perception_v7(
        image_data, latitude, longitude, user_description, photo_type
    ))


# ============================================================
# Layer 5: Curiosity Expansion (å¥½å¥‡å¿ƒæ‰©å±•)
# ============================================================

@dataclass
class MindmapNode:
    """Mindmap èŠ‚ç‚¹"""
    id: str
    title: str
    content: str
    node_type: str = "branch"  # root/branch/leaf
    children: list = field(default_factory=list)
    expanded: bool = False
    depth: int = 0


async def generate_curiosity_questions(insights: list[dict], perception: str) -> list[dict]:
    """
    ä»æ´è§ä¸­ç”Ÿæˆå¥½å¥‡å¿ƒé—®é¢˜

    Returns:
        list of {"question": str, "topic": str, "context": str}
    """
    insights_text = "\n".join([
        f"- {i.get('title', '')}: {i.get('explanation', '')[:100]}..."
        for i in insights
    ])

    prompt = f"""åŸºäºä»¥ä¸‹åˆ†ææ´è§ï¼Œç”Ÿæˆç”¨æˆ·å¯èƒ½æ„Ÿå…´è¶£çš„æ¢ç´¢é—®é¢˜ã€‚

## å›¾ç‰‡å†…å®¹
{perception}

## åˆ†ææ´è§
{insights_text}

## ä»»åŠ¡
æå–æ´è§ä¸­æåˆ°çš„å…·ä½“åè¯ã€äººç‰©ã€æ¦‚å¿µã€ç°è±¡ï¼Œç”Ÿæˆ 4-6 ä¸ªå¼•å¯¼ç”¨æˆ·æ·±å…¥æ¢ç´¢çš„é—®é¢˜ã€‚

## é—®é¢˜è®¾è®¡åŸåˆ™
1. å…·ä½“åŒ–ï¼šé’ˆå¯¹å…·ä½“äº‹ç‰©ï¼ˆå¦‚"å¢¨è¥¿å“¥é£è“¬æ˜¯ä»€ä¹ˆï¼Ÿ"è€Œé"è¿™èŠ±æ˜¯ä»€ä¹ˆï¼Ÿ"ï¼‰
2. æ•…äº‹æ€§ï¼šæŒ–æ˜èƒŒåçš„äººç‰©/å†å²ï¼ˆå¦‚"XXçš„åˆ›å§‹äººæ˜¯è°ï¼Ÿ"ï¼‰
3. å…³è”æ€§ï¼šæ¢ç´¢äº‹ç‰©ä¹‹é—´çš„è”ç³»ï¼ˆå¦‚"ä¸ºä»€ä¹ˆXXä¼šå‡ºç°åœ¨YYï¼Ÿ"ï¼‰
4. æ·±åº¦æ€§ï¼šå¼•å¯¼æ€è€ƒæ›´æ·±å±‚åŸå› ï¼ˆå¦‚"ä¸ºä»€ä¹ˆè¿™ç§è®¾è®¡åœ¨æ—¥æœ¬æµè¡Œï¼Ÿ"ï¼‰

## è¾“å‡º JSON
{{
    "questions": [
        {{
            "question": "å®Œæ•´çš„é—®é¢˜å¥å­",
            "topic": "æ ¸å¿ƒä¸»é¢˜è¯ï¼ˆ2-4å­—ï¼‰",
            "context": "ä¸ºä»€ä¹ˆè¿™ä¸ªé—®é¢˜æœ‰è¶£ï¼ˆ1å¥è¯ï¼‰",
            "keywords": ["æœç´¢å…³é”®è¯1", "æœç´¢å…³é”®è¯2"]
        }}
    ]
}}
"""

    try:
        response = await llm_text(prompt, json_mode=True)
        result = parse_json_response(response, {})
        if not isinstance(result, dict):
            return []
        return result.get("questions", [])
    except Exception as e:
        print(f"ç”Ÿæˆé—®é¢˜å¤±è´¥: {e}")
        return []


async def generate_mindmap(question: str, topic: str, context: str, keywords: list[str]) -> dict:
    """
    ä¸ºä¸€ä¸ªé—®é¢˜ç”Ÿæˆå±‚å±‚é€’è¿›çš„ Mindmap ç»“æ„

    Returns:
        Mindmap structure with root and branches
    """
    # å…ˆæœç´¢è·å–ä¿¡æ¯
    search_query = " ".join(keywords) if keywords else topic
    search_result = await search_grounding(search_query, question)

    prompt = f"""åŸºäºæœç´¢ç»“æœï¼Œä¸ºç”¨æˆ·æ„å»ºä¸€ä¸ªçŸ¥è¯† Mindmapã€‚

## ç”¨æˆ·é—®é¢˜
{question}

## ä¸»é¢˜
{topic}

## æœç´¢ç»“æœ
{search_result.get('answer', '')[:2000]}

## ä»»åŠ¡
æ„å»ºä¸€ä¸ªå±‚å±‚é€’è¿›çš„çŸ¥è¯†ç»“æ„ï¼Œå¸®åŠ©ç”¨æˆ·å»ºç«‹å¿ƒæ™ºæ¨¡å‹ã€‚

## Mindmap è®¾è®¡åŸåˆ™
1. æ ¹èŠ‚ç‚¹ï¼šæ ¸å¿ƒæ¦‚å¿µçš„ç®€æ´å®šä¹‰
2. ä¸€çº§åˆ†æ”¯ï¼š3-4ä¸ªå…³é”®ç»´åº¦ï¼ˆæ˜¯ä»€ä¹ˆ/ä¸ºä»€ä¹ˆ/æ€ä¹ˆæ ·/å…³è”ï¼‰
3. äºŒçº§åˆ†æ”¯ï¼šæ¯ä¸ªç»´åº¦ä¸‹2-3ä¸ªå…·ä½“è¦ç‚¹
4. æ¯ä¸ªèŠ‚ç‚¹éƒ½åº”è¯¥ç®€æ´æœ‰åŠ›ï¼ŒåƒçŸ¥è¯†å¡ç‰‡

## è¾“å‡º JSON
{{
    "root": {{
        "title": "æ ¸å¿ƒæ¦‚å¿µåç§°",
        "summary": "ä¸€å¥è¯æ ¸å¿ƒå®šä¹‰",
        "emoji": "åˆé€‚çš„emoji"
    }},
    "branches": [
        {{
            "id": "branch_1",
            "title": "åˆ†æ”¯æ ‡é¢˜ï¼ˆå¦‚ï¼šèµ·æºï¼‰",
            "emoji": "ğŸŒ±",
            "summary": "2-3å¥è¯æ¦‚è¿°",
            "key_points": [
                {{
                    "title": "è¦ç‚¹æ ‡é¢˜",
                    "content": "å…·ä½“å†…å®¹ï¼ˆ1-2å¥è¯ï¼‰",
                    "expandable": true,
                    "expand_query": "å¦‚æœç”¨æˆ·æƒ³æ·±å…¥ï¼Œåº”è¯¥æœç´¢ä»€ä¹ˆ"
                }}
            ]
        }}
    ],
    "fun_fact": "ä¸€ä¸ªæœ‰è¶£çš„å†·çŸ¥è¯†",
    "related_questions": ["å»¶ä¼¸é—®é¢˜1", "å»¶ä¼¸é—®é¢˜2"]
}}
"""

    try:
        response = await llm_text(prompt, json_mode=True, temperature=0.6)
        result = parse_json_response(response, {})
        if not isinstance(result, dict):
            return {"error": "è§£æå¤±è´¥", "raw": str(response)[:200]}

        # éªŒè¯å¿…è¦å­—æ®µ
        if not result.get("root"):
            # å°è¯•æ„å»ºé»˜è®¤ç»“æ„
            result["root"] = {
                "title": topic or question[:20],
                "summary": search_result.get("answer", "")[:100] + "...",
                "emoji": "ğŸ“š"
            }

        if not result.get("branches"):
            result["branches"] = [{
                "id": "branch_1",
                "title": "åŸºæœ¬ä¿¡æ¯",
                "emoji": "ğŸ“Œ",
                "summary": search_result.get("answer", "")[:200],
                "key_points": []
            }]

        result["search_sources"] = search_result.get("sources", [])
        return result
    except Exception as e:
        return {"error": str(e), "search_answer": search_result.get("answer", "")[:300]}


async def expand_branch(branch_title: str, expand_query: str, parent_context: str) -> dict:
    """
    å±•å¼€ Mindmap çš„æŸä¸ªåˆ†æ”¯ï¼Œè·å–æ›´æ·±å…¥çš„å†…å®¹
    """
    search_result = await search_grounding(expand_query, parent_context)

    prompt = f"""ç”¨æˆ·æƒ³æ·±å…¥äº†è§£ Mindmap ä¸­çš„æŸä¸ªåˆ†æ”¯ã€‚

## åˆ†æ”¯ä¸»é¢˜
{branch_title}

## ä¸Šä¸‹æ–‡
{parent_context}

## æœç´¢ç»“æœ
{search_result.get('answer', '')[:1500]}

## ä»»åŠ¡
æä¾›è¿™ä¸ªåˆ†æ”¯çš„æ·±å…¥è§£è¯»ï¼ŒåŒ…æ‹¬ï¼š
1. æ›´è¯¦ç»†çš„è§£é‡Š
2. å…·ä½“çš„ä¾‹å­æˆ–æ¡ˆä¾‹
3. ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦
4. å¯èƒ½çš„è¿›ä¸€æ­¥æ¢ç´¢æ–¹å‘

## è¾“å‡º JSON
{{
    "deep_explanation": "è¯¦ç»†è§£é‡Šï¼ˆ3-5å¥è¯ï¼‰",
    "examples": ["å…·ä½“ä¾‹å­1", "å…·ä½“ä¾‹å­2"],
    "significance": "ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦ï¼ˆ1-2å¥è¯ï¼‰",
    "go_deeper": [
        {{
            "direction": "æ¢ç´¢æ–¹å‘",
            "query": "æœç´¢è¯"
        }}
    ]
}}
"""

    try:
        response = await llm_text(prompt, json_mode=True, temperature=0.5)
        result = parse_json_response(response, {})
        if not isinstance(result, dict):
            return {"error": "è§£æå¤±è´¥"}
        return result
    except Exception as e:
        return {"error": str(e)}


# åŒæ­¥å…¥å£
def generate_curiosity_questions_sync(insights: list[dict], perception: str) -> list[dict]:
    """åŒæ­¥ç‰ˆæœ¬ï¼šç”Ÿæˆå¥½å¥‡å¿ƒé—®é¢˜"""
    return asyncio.run(generate_curiosity_questions(insights, perception))


def generate_mindmap_sync(question: str, topic: str, context: str, keywords: list[str]) -> dict:
    """åŒæ­¥ç‰ˆæœ¬ï¼šç”Ÿæˆ Mindmap"""
    return asyncio.run(generate_mindmap(question, topic, context, keywords))


def expand_branch_sync(branch_title: str, expand_query: str, parent_context: str) -> dict:
    """åŒæ­¥ç‰ˆæœ¬ï¼šå±•å¼€åˆ†æ”¯"""
    return asyncio.run(expand_branch(branch_title, expand_query, parent_context))
